{"cells":[{"cell_type":"markdown","id":"37BV7-CMEbMj","metadata":{"id":"37BV7-CMEbMj"},"source":["# Data Processing Approach for Portfolio Project\n","\n","## Project Title: Customer Product Recommendation System\n","\n","## Student Name: Larissa Bizimungu\n","\n","---\n","\n","### 1. **Data Sources and Aggregation:**\n","\n","\n","## - List all sources of data for the project. **You must consider sources outside kaggle, google datasets** (insert links where necessary to online platforms,research papers etc)\n","\n","\n","**The sources to the data on Customers Product Recommendation System stems a big range of sources from online stores, to reaserch papers,**  \n","**and among those sources we have:**  \n","\n","**- Amazon Customers Review Dataset**  \n","**- Alibaba/Taobao User Behavior Dataset**  \n","**- data.world datasets**  \n","**- UCI Machine Learning Repository**  \n","**- Harvard Dataverse**  \n","**- Web scraping (with proper permissions) of product review websites, etc**  \n","     \n","### Links: Below is a link to a page with multiple datasets from Amazon based on different products such as beuty products, books, cds, ect  \n","\n","https://amazon-reviews-2023.github.io/  \n","\n","### Links: below is another link to multiple datasets on products review from World.dat, a collection of a wide range of datasets across various interests  \n","\n","https://data.world/search?context=community&q=&type=resources  \n","  \n","*I ended up using two datasets on Books review*  \n","  \n","        \n","## - Determine if data aggregation from multiple sources is necessary for comprehensive analysis.  \n","  \n","\n","For a comprehensive customer product recommendation system, data aggregation from multiple sources is indeed necessary. Here's why:  \n","\n","**1. Diverse product range:**   \n","Different sources may cover various product categories. For example, Amazon datasets might have a wide range of products, while a specific dataset from data.world might focus on books. Aggregating these provides a more comprehensive product catalog.  \n","\n","**2. User behavior insights:**   \n","Combining data from sources like Amazon Customer Reviews and Alibaba/Taobao User Behavior Dataset can provide a more holistic view of user preferences across different platforms and cultures.  \n","  \n","**3. Cross-validation:**  \n","Using multiple sources allows for cross-validation of trends and patterns, increasing the reliability of your analysis.\n","Overcoming data limitations: Single sources may have limitations in terms of data quality, completeness, or recency. Aggregating from multiple sources can help fill these gaps.  \n","  \n","**4. Richer feature set:**  \n","Different datasets might offer unique features. For instance, Amazon might provide detailed product attributes, while web-scraped data could offer real-time pricing information.  \n","\n","**5. Temporal aspects:**  \n","Some datasets might cover different time periods. Aggregating these can provide insights into changing customer preferences over time.\n","  \n","**6. Demographic diversity:**  \n","Different sources might represent various demographic groups, leading to a more inclusive recommendation system.\n","\n","**7. Reducing bias:**   \n","Relying on a single source might introduce biases specific to that platform. Using multiple sources can help in creating a more balanced dataset.\n","\n","**8. Enhanced cold start problem solving:**   \n","For new users or products, having data from multiple sources increases the chances of finding relevant information for initial recommendations.\n","\n","**9. Improved personalization:**    \n","With a broader dataset, you can create more refined user profiles and offer more personalized recommendations."]},{"cell_type":"code","execution_count":null,"id":"K6W_BkY6FGRL","metadata":{"id":"K6W_BkY6FGRL"},"outputs":[],"source":["#insert code if necessary: No code necessary"]},{"cell_type":"markdown","id":"TzyeghJDEjit","metadata":{"id":"TzyeghJDEjit"},"source":["\n","\n","2. **Data Format Transformation:**\n","   - Describe the current format of the data.\n","   - Outline the planned transformation to a unified format suitable for analysis and modeling.\n","\n"," **Your answer for data transformation goes here **\n","\n","3. **Data Exploration:**\n","   - Enumerate the features included in the dataset.\n","   \n","   - Summarize findings from exploratory data analysis (EDA) including distributions, correlations, and outliers.\n","   \n","  **Insert code for data exploration below**\n"]},{"cell_type":"code","execution_count":null,"id":"oYEgIOxSFUHW","metadata":{"id":"oYEgIOxSFUHW"},"outputs":[],"source":["#Include plots for EDA\n"]},{"cell_type":"markdown","id":"tHKtxjFKFNpB","metadata":{"id":"tHKtxjFKFNpB"},"source":["\n","\n","4. **Hypothesis Testing:**\n","   - State any preexisting hypotheses about the data.\n","   - Explain methodologies to empirically test these hypotheses.\n","\n","   **Your answer for Hypothesis Testing goes here **\n","\n","5. **Handling Sparse/Dense Data and Outliers:**\n","   - Assess the density of the data.\n","   - Propose strategies to handle missing data and outliers while maintaining dataset integrity.\n","\n","   **Insert code for Handling Sparse/Dense Data and Outliers below**"]},{"cell_type":"code","execution_count":null,"id":"f_R52s5RE_wj","metadata":{"id":"f_R52s5RE_wj"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"5SS3lD0sGPGe","metadata":{"id":"5SS3lD0sGPGe"},"source":["6. **Data Splitting:**\n","   - Define a methodology to split the dataset into training, validation, and testing sets.\n","   - Ensure randomness and representativeness in each subset.\n","\n","7. **Bias Mitigation:**\n","   - Implement techniques to identify and mitigate biases in the dataset.\n","   - Ensure fairness and equity in data representation.\n","   \n","    **Your answer for Hypothesis Testing goes here **\n","\n"]},{"cell_type":"code","execution_count":null,"id":"iX_5Hl65GEgY","metadata":{"id":"iX_5Hl65GEgY"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"OzGrkCCXGUxV","metadata":{"id":"OzGrkCCXGUxV"},"source":["8. **Features for Model Training:**\n","   - Identify relevant features for training the model.\n","   - Rank features based on their significance to project objectives.\n","\n"," **Your answer for features must be plotted/ show your working code-wise **\n","9. **Types of Data Handling:**\n","   - Classify the types of data (categorical, numerical, etc.) present in the dataset.\n","   - Plan preprocessing steps for each data type.\n","\n","   [**insert text for preprocessing steps**]\n"]},{"cell_type":"code","execution_count":null,"id":"YNkqADAQGbNZ","metadata":{"id":"YNkqADAQGbNZ"},"outputs":[],"source":["#print out relevant features"]},{"cell_type":"markdown","id":"lG_mx92GGX6W","metadata":{"id":"lG_mx92GGX6W"},"source":["\n","10. **Data Transformation for Modeling:**\n","    - Specify methods for transforming raw data into a model-friendly format.\n","    - Detail steps for normalization, scaling, or encoding categorical variables.\n","\n","11. **Data Storage:**\n","    - Determine where and how processed data will be stored.\n","    - Choose suitable storage solutions ensuring accessibility and security.\n","\n","---\n","\n","#### Notes:\n","- This template provides a structured framework for documenting your data processing approach for the portfolio project.\n","- Fill out each section with specific details relevant to your project's requirements and objectives.\n","- Use additional cells as needed to provide comprehensive information."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":5}
