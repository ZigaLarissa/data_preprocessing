{"cells":[{"cell_type":"markdown","id":"37BV7-CMEbMj","metadata":{"id":"37BV7-CMEbMj"},"source":["# Data Processing Approach for Portfolio Project\n","\n","## Project Title: Customer Product Recommendation System\n","\n","## Student Name: Larissa Bizimungu\n","\n","---\n","\n","### 1. **Data Sources and Aggregation:**\n","\n","   #### - List all sources of data for the project. **You must consider sources outside kaggle, google datasets** (insert links where necessary to online platforms,research papers etc)\n","\n","      My source was OpenML, a world wide Machine Leanring Lab. It is an open platform for sharing datasets, algorithms,  \n","      and experiments - to learn how to learn better together. It is where I got the 2 datasets that I am going to be working with.\n","\n","      Amazon electronic Dataset: https://openml.org/search?type=data&status=active&id=45050\n","\n","      Amazon Beuty Products Ratings: https://openml.org/search?type=data&status=active&id=43366 \n","   \n","   #### - Determine if data aggregation from multiple sources is necessary for comprehensive analysis.\n","\n","      In this case, data aggregation is necessary for a comprehensive analysis if we want to gain insights across both product categories  (electronics and beauty).\n","\n","      Aggregating these datasets allows us to:\n","         a) Compare customer behaviors across different product types\n","         b) Identify cross-category purchasing patterns\n","         c) Develop a more robust recommendation system that can suggest products across categories"]},{"cell_type":"code","execution_count":null,"id":"K6W_BkY6FGRL","metadata":{"id":"K6W_BkY6FGRL"},"outputs":[],"source":["#insert code if necessary"]},{"cell_type":"markdown","id":"TzyeghJDEjit","metadata":{"id":"TzyeghJDEjit"},"source":["\n","\n","2. **Data Format Transformation:**\n","   - Describe the current format of the data.\n","   - Outline the planned transformation to a unified format suitable for analysis and modeling.\n","\n"," **Your answer for data transformation goes here **\n","\n","3. **Data Exploration:**\n","   - Enumerate the features included in the dataset.\n","   \n","   - Summarize findings from exploratory data analysis (EDA) including distributions, correlations, and outliers.\n","   \n","  **Insert code for data exploration below**\n"]},{"cell_type":"code","execution_count":null,"id":"oYEgIOxSFUHW","metadata":{"id":"oYEgIOxSFUHW"},"outputs":[],"source":["#Include plots for EDA\n"]},{"cell_type":"markdown","id":"tHKtxjFKFNpB","metadata":{"id":"tHKtxjFKFNpB"},"source":["\n","\n","4. **Hypothesis Testing:**\n","   - State any preexisting hypotheses about the data.\n","   - Explain methodologies to empirically test these hypotheses.\n","\n","   **Your answer for Hypothesis Testing goes here **\n","\n","5. **Handling Sparse/Dense Data and Outliers:**\n","   - Assess the density of the data.\n","   - Propose strategies to handle missing data and outliers while maintaining dataset integrity.\n","\n","   **Insert code for Handling Sparse/Dense Data and Outliers below**"]},{"cell_type":"code","execution_count":null,"id":"f_R52s5RE_wj","metadata":{"id":"f_R52s5RE_wj"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"5SS3lD0sGPGe","metadata":{"id":"5SS3lD0sGPGe"},"source":["6. **Data Splitting:**\n","   - Define a methodology to split the dataset into training, validation, and testing sets.\n","   - Ensure randomness and representativeness in each subset.\n","\n","7. **Bias Mitigation:**\n","   - Implement techniques to identify and mitigate biases in the dataset.\n","   - Ensure fairness and equity in data representation.\n","   \n","    **Your answer for Hypothesis Testing goes here **\n","\n"]},{"cell_type":"code","execution_count":null,"id":"iX_5Hl65GEgY","metadata":{"id":"iX_5Hl65GEgY"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"OzGrkCCXGUxV","metadata":{"id":"OzGrkCCXGUxV"},"source":["8. **Features for Model Training:**\n","   - Identify relevant features for training the model.\n","   - Rank features based on their significance to project objectives.\n","\n"," **Your answer for features must be plotted/ show your working code-wise **\n","9. **Types of Data Handling:**\n","   - Classify the types of data (categorical, numerical, etc.) present in the dataset.\n","   - Plan preprocessing steps for each data type.\n","\n","   [**insert text for preprocessing steps**]\n"]},{"cell_type":"code","execution_count":null,"id":"YNkqADAQGbNZ","metadata":{"id":"YNkqADAQGbNZ"},"outputs":[],"source":["#print out relevant features"]},{"cell_type":"markdown","id":"lG_mx92GGX6W","metadata":{"id":"lG_mx92GGX6W"},"source":["\n","10. **Data Transformation for Modeling:**\n","    - Specify methods for transforming raw data into a model-friendly format.\n","    - Detail steps for normalization, scaling, or encoding categorical variables.\n","\n","11. **Data Storage:**\n","    - Determine where and how processed data will be stored.\n","    - Choose suitable storage solutions ensuring accessibility and security.\n","\n","---\n","\n","#### Notes:\n","- This template provides a structured framework for documenting your data processing approach for the portfolio project.\n","- Fill out each section with specific details relevant to your project's requirements and objectives.\n","- Use additional cells as needed to provide comprehensive information."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":5}
